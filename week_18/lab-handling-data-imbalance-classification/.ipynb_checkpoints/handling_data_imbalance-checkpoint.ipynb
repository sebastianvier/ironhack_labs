{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "ede10ddf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from imblearn.under_sampling import TomekLinks\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be68003b",
   "metadata": {},
   "source": [
    "- Read that data into Python and call the dataframe `churnData`.\n",
    "- Check the datatypes of all the columns in the data. You would see that the column `TotalCharges` is object type. Convert this column into numeric type using `pd.to_numeric` function.\n",
    "- Check for null values in the dataframe. Replace the null values.\n",
    "- Use the following features: `tenure`, `SeniorCitizen`, `MonthlyCharges` and `TotalCharges`:\n",
    "  - Scale the features either by using normalizer or a standard scaler.\n",
    "  - Split the data into a training set and a test set.\n",
    "  - Fit a logistic regression model on the training data.\n",
    "  - Check the accuracy on the test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e16e882e",
   "metadata": {},
   "outputs": [],
   "source": [
    "churn_data = pd.read_csv('files_for_lab/Customer-Churn.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "baceb5a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_zero(x):\n",
    "    if x == ' ':\n",
    "        return 0\n",
    "    else:\n",
    "        return float(x)\n",
    "\n",
    "churn_data['TotalCharges'] = churn_data.TotalCharges.apply(to_zero)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "825ace6c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 7043 entries, 0 to 7042\n",
      "Data columns (total 16 columns):\n",
      " #   Column            Non-Null Count  Dtype  \n",
      "---  ------            --------------  -----  \n",
      " 0   gender            7043 non-null   object \n",
      " 1   SeniorCitizen     7043 non-null   int64  \n",
      " 2   Partner           7043 non-null   object \n",
      " 3   Dependents        7043 non-null   object \n",
      " 4   tenure            7043 non-null   int64  \n",
      " 5   PhoneService      7043 non-null   object \n",
      " 6   OnlineSecurity    7043 non-null   object \n",
      " 7   OnlineBackup      7043 non-null   object \n",
      " 8   DeviceProtection  7043 non-null   object \n",
      " 9   TechSupport       7043 non-null   object \n",
      " 10  StreamingTV       7043 non-null   object \n",
      " 11  StreamingMovies   7043 non-null   object \n",
      " 12  Contract          7043 non-null   object \n",
      " 13  MonthlyCharges    7043 non-null   float64\n",
      " 14  TotalCharges      7043 non-null   float64\n",
      " 15  Churn             7043 non-null   object \n",
      "dtypes: float64(2), int64(2), object(12)\n",
      "memory usage: 880.5+ KB\n"
     ]
    }
   ],
   "source": [
    "churn_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b0ea1f99",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "gender              0\n",
       "SeniorCitizen       0\n",
       "Partner             0\n",
       "Dependents          0\n",
       "tenure              0\n",
       "PhoneService        0\n",
       "OnlineSecurity      0\n",
       "OnlineBackup        0\n",
       "DeviceProtection    0\n",
       "TechSupport         0\n",
       "StreamingTV         0\n",
       "StreamingMovies     0\n",
       "Contract            0\n",
       "MonthlyCharges      0\n",
       "TotalCharges        0\n",
       "Churn               0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "churn_data.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "b03a55d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = churn_data['Churn']\n",
    "X = churn_data[['tenure', 'SeniorCitizen', 'MonthlyCharges', 'TotalCharges']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c87d86c",
   "metadata": {},
   "source": [
    "### Model 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "035490a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          No       0.00      0.00      0.00      1721\n",
      "         Yes       0.26      1.00      0.41       604\n",
      "\n",
      "    accuracy                           0.26      2325\n",
      "   macro avg       0.13      0.50      0.21      2325\n",
      "weighted avg       0.07      0.26      0.11      2325\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=44)\n",
    "scaler = StandardScaler().fit(X_train)\n",
    "X_train_t = scaler.transform(X_train)\n",
    "X_train_t = pd.DataFrame(X_train_t, columns=X.columns)\n",
    "\n",
    "lgr = LogisticRegression().fit(X_train_t, y_train)\n",
    "prediction = lgr.predict(X_test)\n",
    "\n",
    "print(classification_report(y_test, prediction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "81b41422",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "No     5174\n",
       "Yes    1869\n",
       "Name: Churn, dtype: int64"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5590f617",
   "metadata": {},
   "source": [
    "Ok, that is something new. I got the problem that I thought I would get, but the other way around, instead of getting a full recall on the data that had the more counts I got a full recall of the other data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4bae96d",
   "metadata": {},
   "source": [
    "### Model 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "706994c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          No       0.00      0.00      0.00      1709\n",
      "         Yes       0.26      1.00      0.42       616\n",
      "\n",
      "    accuracy                           0.26      2325\n",
      "   macro avg       0.13      0.50      0.21      2325\n",
      "weighted avg       0.07      0.26      0.11      2325\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=50)\n",
    "scaler = StandardScaler().fit(X_train)\n",
    "X_train_t = scaler.transform(X_train)\n",
    "X_train_t = pd.DataFrame(X_train_t, columns=X.columns)\n",
    "\n",
    "lgr = LogisticRegression().fit(X_train_t, y_train)\n",
    "prediction = lgr.predict(X_test)\n",
    "\n",
    "print(classification_report(y_test, prediction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "0a5aea3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No     3465\n",
      "Yes    3465\n",
      "Name: Churn, dtype: int64\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          No       0.90      0.69      0.78      1709\n",
      "         Yes       0.47      0.78      0.59       616\n",
      "\n",
      "    accuracy                           0.71      2325\n",
      "   macro avg       0.68      0.73      0.68      2325\n",
      "weighted avg       0.78      0.71      0.73      2325\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=50)\n",
    "\n",
    "## Concat the data\n",
    "full_train = pd.concat([X_train, y_train],axis=1)\n",
    "\n",
    "## Balance the data\n",
    "train_no = full_train[full_train.Churn == 'No']\n",
    "length = len(C_no)\n",
    "train_yes = full_train[full_train.Churn == 'Yes'].sample(length, replace=True)\n",
    "full_train = pd.concat([train_no, train_yes])\n",
    "print(full_train.Churn.value_counts())\n",
    "\n",
    "\n",
    "## Split data again\n",
    "X_train = full_train.drop(['Churn'],axis=1)\n",
    "y_train = full_train[['Churn']]\n",
    "\n",
    "## Scale data\n",
    "scaler = StandardScaler().fit(X_train)\n",
    "scaler.transform(X_train)\n",
    "X_train = pd.DataFrame(X_train, columns=X.columns)\n",
    "\n",
    "\n",
    "## Run model\n",
    "lgr = LogisticRegression().fit(X_train, y_train)\n",
    "prediction = lgr.predict(X_test)\n",
    "classification_1 = classification_report(y_test, prediction)\n",
    "print(classification_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "12464b8a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          No       0.83      0.89      0.86      1709\n",
      "         Yes       0.62      0.49      0.55       616\n",
      "\n",
      "    accuracy                           0.79      2325\n",
      "   macro avg       0.73      0.69      0.70      2325\n",
      "weighted avg       0.77      0.79      0.78      2325\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=50)\n",
    "\n",
    "## Concat the data\n",
    "full_train = pd.concat([X_train, y_train],axis=1)\n",
    "\n",
    "## Balance the data\n",
    "C_yes = full_train[full_train.Churn == 'Yes']\n",
    "length = len(C_no)\n",
    "C_no = full_train[full_train.Churn == 'No'].sample(length, replace=True)\n",
    "full_train = pd.concat([C_yes, C_no])\n",
    "\n",
    "## Split data again\n",
    "X_train = full_train.drop(['Churn'],axis=1)\n",
    "y_train = full_train[['Churn']]\n",
    "\n",
    "## Scale data\n",
    "scaler = StandardScaler().fit(X_train)\n",
    "scaler.transform(X_train)\n",
    "X_train = pd.DataFrame(X_train, columns=X.columns)\n",
    "\n",
    "## Run model\n",
    "lgr = LogisticRegression().fit(X_train, y_train)\n",
    "prediction = lgr.predict(X_test)\n",
    "\n",
    "classification_2 = classification_report(y_test, prediction)\n",
    "print(classification_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "c32eb69e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          No       0.89      0.70      0.79      1709\n",
      "         Yes       0.48      0.75      0.58       616\n",
      "\n",
      "    accuracy                           0.72      2325\n",
      "   macro avg       0.68      0.73      0.68      2325\n",
      "weighted avg       0.78      0.72      0.73      2325\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=50)\n",
    "\n",
    "over_sampler = SMOTE().fit(X_train, y_train)\n",
    "X_res, y_res = over_sampler.fit_resample(X, y)\n",
    "\n",
    "# ## Scale data\n",
    "scaler = StandardScaler().fit(X_res)\n",
    "scaler.transform(X_res)\n",
    "\n",
    "## Run model\n",
    "lgr = LogisticRegression().fit(X_res, y_res)\n",
    "prediction = lgr.predict(X_test)\n",
    "classification_3 = classification_report(y_test, prediction)\n",
    "print(classification_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "65af4946",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          No       0.89      0.66      0.76      1709\n",
      "         Yes       0.45      0.78      0.57       616\n",
      "\n",
      "    accuracy                           0.69      2325\n",
      "   macro avg       0.67      0.72      0.67      2325\n",
      "weighted avg       0.78      0.69      0.71      2325\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=50)\n",
    "\n",
    "under_sampler = TomekLinks(n_jobs=4).fit(X_train, y_train)\n",
    "X_res, y_res = under_sampler.fit_resample(X, y)\n",
    "\n",
    "# ## Scale data\n",
    "scaler = StandardScaler().fit(X_res)\n",
    "scaler.transform(X_res)\n",
    "\n",
    "## Run model\n",
    "lgr = LogisticRegression().fit(X_res, y_res)\n",
    "prediction = lgr.predict(X_test)\n",
    "classification_4 = classification_report(y_test, prediction)\n",
    "print(classification_4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "4b12e962",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          No       0.90      0.69      0.78      1709\n",
      "         Yes       0.47      0.78      0.59       616\n",
      "\n",
      "    accuracy                           0.71      2325\n",
      "   macro avg       0.68      0.73      0.68      2325\n",
      "weighted avg       0.78      0.71      0.73      2325\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          No       0.83      0.89      0.86      1709\n",
      "         Yes       0.62      0.49      0.55       616\n",
      "\n",
      "    accuracy                           0.79      2325\n",
      "   macro avg       0.73      0.69      0.70      2325\n",
      "weighted avg       0.77      0.79      0.78      2325\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          No       0.89      0.70      0.79      1709\n",
      "         Yes       0.48      0.75      0.58       616\n",
      "\n",
      "    accuracy                           0.72      2325\n",
      "   macro avg       0.68      0.73      0.68      2325\n",
      "weighted avg       0.78      0.72      0.73      2325\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          No       0.89      0.66      0.76      1709\n",
      "         Yes       0.45      0.78      0.57       616\n",
      "\n",
      "    accuracy                           0.69      2325\n",
      "   macro avg       0.67      0.72      0.67      2325\n",
      "weighted avg       0.78      0.69      0.71      2325\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_1)\n",
    "print(classification_2)\n",
    "print(classification_3)\n",
    "print(classification_4)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
